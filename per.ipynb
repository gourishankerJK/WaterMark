{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning GPU2 with 16063.0 free MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 2 has a total capacity of 31.74 GiB of which 119.38 MiB is free. Process 1834150 has 8.00 GiB memory in use. Process 1852644 has 7.98 GiB memory in use. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 1.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[1;32m     22\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(get_free_gpu()) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/transformers/modeling_utils.py:2576\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/NLP/WaterMark/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 2 has a total capacity of 31.74 GiB of which 119.38 MiB is free. Process 1834150 has 8.00 GiB memory in use. Process 1852644 has 7.98 GiB memory in use. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, and 1.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_name = './llama-2-7b-hf'\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def get_free_gpu():\n",
    "    gpu_stats = subprocess.check_output([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"])\n",
    "    gpu_stats = gpu_stats.decode('utf-8')\n",
    "    gpu_df = pd.read_csv(io.StringIO(gpu_stats))\n",
    "    gpu_df[\"memory.free\"] = gpu_df[' memory.free [MiB]']\n",
    "    gpu_df['memory.free'] = gpu_df['memory.free'].map(lambda x: x.rstrip(' [MiB]')).astype('float32')\n",
    "    idx = gpu_df['memory.free'].idxmax()\n",
    "    print('Returning GPU{} with {} free MiB'.format(idx, gpu_df.iloc[idx]['memory.free']))\n",
    "    return idx\n",
    "device = torch.device(\"cuda:\" + str(get_free_gpu()) if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(document , file):\n",
    "    p = []\n",
    "    count = 0\n",
    "    for text in document:\n",
    "        encodings = tokenizer(\"\".join(text), return_tensors=\"pt\")\n",
    "        max_length = model.config.max_length\n",
    "        stride = 1024\n",
    "        seq_len = encodings.input_ids.size(1)\n",
    "        nlls = []\n",
    "        prev_end_loc = 0\n",
    "        for begin_loc in (range(0, seq_len, stride)):\n",
    "            end_loc = min(begin_loc + max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "            input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, labels=target_ids)\n",
    "                neg_log_likelihood = outputs.loss\n",
    "\n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc == seq_len:\n",
    "                break\n",
    "\n",
    "        ppl = torch.exp(torch.stack(nlls , dim = 0))\n",
    "        p.append({f\"per_of_{file}\": ppl.item() , f\"seq_of_{file}\" : seq_len})\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphraed_PivotTranslation\n",
      "--> semantics\n",
      "----> Dataset/Attacked/NewData//Paraphraed_PivotTranslation/semantics/llm_watermarked_semantics_pivot_translated.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "--> sir\n",
      "----> Dataset/Attacked/NewData//Paraphraed_PivotTranslation/sir/llm_watermarked_sir_pivot_translated.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "--> kwg\n",
      "----> Dataset/Attacked/NewData//Paraphraed_PivotTranslation/kwg/llm_watermarked_kwg_pivot_translated.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "Paraphrased_NormalTranslation\n",
      "--> semantics\n",
      "----> Dataset/Attacked/NewData//Paraphrased_NormalTranslation/semantics/llm_watermarked_semantics_translated.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "--> sir\n",
      "----> Dataset/Attacked/NewData//Paraphrased_NormalTranslation/sir/llm_watermarked_sir_translated.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "--> kwg\n",
      "----> Dataset/Attacked/NewData//Paraphrased_NormalTranslation/kwg/llm_watermarked_kwg_translated.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "translation_paraphrased\n",
      "--> semantics\n",
      "----> Dataset/Attacked/NewData//translation_paraphrased/semantics/watermark_dipper0.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "--> SIR\n",
      "----> Dataset/Attacked/NewData//translation_paraphrased/SIR/SIRrephrased4.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n",
      "--> kwg\n",
      "----> Dataset/Attacked/NewData//translation_paraphrased/kwg/rephrased2.pkl\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2277690/4008941631.py\", line 21, in <module>\n",
      "    recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
      "NameError: name 'get_perplexity' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import pickle\n",
    "import traceback\n",
    "directory = \"Dataset/Attacked/\"\n",
    "\n",
    "directories = ['Dataset/Attacked/NewData/']\n",
    "recursive_para = {}\n",
    "for directory in directories:\n",
    "        for folder in os.listdir(directory):\n",
    "            print(folder)\n",
    "            for subfolder in os.listdir(directory + folder):\n",
    "                print(\"-->\" , subfolder)\n",
    "                try :\n",
    "                    for i , files in enumerate(os.listdir(directory  + folder + \"/\" + subfolder)):\n",
    "                        file = f\"{directory}/{folder}/{subfolder}/{files}\"\n",
    "                        recursive_para[file] = recursive_para.get(file , [])\n",
    "                    \n",
    "                        with open(file , \"rb\") as f:\n",
    "                                data = pickle.load(f)\n",
    "                        recursive_para[file].append(get_perplexity(data , f\"{folder}_{subfolder}_{i}\"))\n",
    "                except Exception as e:\n",
    "                    print(traceback.format_exc())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per_of_RERERETE_semantics_0</th>\n",
       "      <th>seq_of_RERERETE_semantics_0</th>\n",
       "      <th>per_of_RERERETE_semantics_1</th>\n",
       "      <th>seq_of_RERERETE_semantics_1</th>\n",
       "      <th>per_of_RERERETE_semantics_2</th>\n",
       "      <th>seq_of_RERERETE_semantics_2</th>\n",
       "      <th>per_of_RERERETE_semantics_3</th>\n",
       "      <th>seq_of_RERERETE_semantics_3</th>\n",
       "      <th>per_of_RERERETE_semantics_4</th>\n",
       "      <th>seq_of_RERERETE_semantics_4</th>\n",
       "      <th>...</th>\n",
       "      <th>per_of_RNormalTranslation_kwg_0</th>\n",
       "      <th>seq_of_RNormalTranslation_kwg_0</th>\n",
       "      <th>per_of_RNormalTranslation_sir_0</th>\n",
       "      <th>seq_of_RNormalTranslation_sir_0</th>\n",
       "      <th>per_of_RPivotTranslation_semantics_0</th>\n",
       "      <th>seq_of_RPivotTranslation_semantics_0</th>\n",
       "      <th>per_of_RPivotTranslation_kwg_0</th>\n",
       "      <th>seq_of_RPivotTranslation_kwg_0</th>\n",
       "      <th>per_of_RPivotTranslation_sir_0</th>\n",
       "      <th>seq_of_RPivotTranslation_sir_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.683483</td>\n",
       "      <td>179</td>\n",
       "      <td>97.792519</td>\n",
       "      <td>146</td>\n",
       "      <td>94.723030</td>\n",
       "      <td>195</td>\n",
       "      <td>12.597280</td>\n",
       "      <td>288</td>\n",
       "      <td>15.162140</td>\n",
       "      <td>213</td>\n",
       "      <td>...</td>\n",
       "      <td>40.119129</td>\n",
       "      <td>303</td>\n",
       "      <td>40.119129</td>\n",
       "      <td>197</td>\n",
       "      <td>33.094795</td>\n",
       "      <td>227</td>\n",
       "      <td>33.094795</td>\n",
       "      <td>224</td>\n",
       "      <td>33.094795</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.493668</td>\n",
       "      <td>72</td>\n",
       "      <td>48.557602</td>\n",
       "      <td>72</td>\n",
       "      <td>29.088301</td>\n",
       "      <td>81</td>\n",
       "      <td>61.883507</td>\n",
       "      <td>122</td>\n",
       "      <td>38.476810</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>69.377960</td>\n",
       "      <td>239</td>\n",
       "      <td>287.683105</td>\n",
       "      <td>340</td>\n",
       "      <td>74.275902</td>\n",
       "      <td>161</td>\n",
       "      <td>74.686523</td>\n",
       "      <td>230</td>\n",
       "      <td>66.842415</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.961502</td>\n",
       "      <td>152</td>\n",
       "      <td>42.149338</td>\n",
       "      <td>100</td>\n",
       "      <td>32.718262</td>\n",
       "      <td>162</td>\n",
       "      <td>13.673713</td>\n",
       "      <td>171</td>\n",
       "      <td>17.271112</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>11.553406</td>\n",
       "      <td>330</td>\n",
       "      <td>11.553406</td>\n",
       "      <td>495</td>\n",
       "      <td>43.565704</td>\n",
       "      <td>250</td>\n",
       "      <td>44.815575</td>\n",
       "      <td>243</td>\n",
       "      <td>11.553406</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.140652</td>\n",
       "      <td>67</td>\n",
       "      <td>29.432497</td>\n",
       "      <td>46</td>\n",
       "      <td>28.021360</td>\n",
       "      <td>68</td>\n",
       "      <td>24.140652</td>\n",
       "      <td>93</td>\n",
       "      <td>26.303492</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>34.435089</td>\n",
       "      <td>231</td>\n",
       "      <td>50.323181</td>\n",
       "      <td>84</td>\n",
       "      <td>60.475807</td>\n",
       "      <td>93</td>\n",
       "      <td>85.276672</td>\n",
       "      <td>166</td>\n",
       "      <td>21.317049</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.526081</td>\n",
       "      <td>76</td>\n",
       "      <td>45.434662</td>\n",
       "      <td>78</td>\n",
       "      <td>60.044567</td>\n",
       "      <td>82</td>\n",
       "      <td>48.849869</td>\n",
       "      <td>231</td>\n",
       "      <td>31.012699</td>\n",
       "      <td>213</td>\n",
       "      <td>...</td>\n",
       "      <td>71.921051</td>\n",
       "      <td>308</td>\n",
       "      <td>70.718254</td>\n",
       "      <td>117</td>\n",
       "      <td>170.488129</td>\n",
       "      <td>237</td>\n",
       "      <td>62.984909</td>\n",
       "      <td>223</td>\n",
       "      <td>71.921051</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>71.033676</td>\n",
       "      <td>136</td>\n",
       "      <td>109.698463</td>\n",
       "      <td>140</td>\n",
       "      <td>71.033676</td>\n",
       "      <td>153</td>\n",
       "      <td>71.033676</td>\n",
       "      <td>208</td>\n",
       "      <td>79.333473</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>310.886993</td>\n",
       "      <td>272</td>\n",
       "      <td>179.795166</td>\n",
       "      <td>108</td>\n",
       "      <td>179.795166</td>\n",
       "      <td>217</td>\n",
       "      <td>179.795166</td>\n",
       "      <td>188</td>\n",
       "      <td>179.795166</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>14.939868</td>\n",
       "      <td>160</td>\n",
       "      <td>12.893393</td>\n",
       "      <td>153</td>\n",
       "      <td>26.084930</td>\n",
       "      <td>162</td>\n",
       "      <td>55.187366</td>\n",
       "      <td>207</td>\n",
       "      <td>38.400303</td>\n",
       "      <td>181</td>\n",
       "      <td>...</td>\n",
       "      <td>109.062309</td>\n",
       "      <td>308</td>\n",
       "      <td>53.918785</td>\n",
       "      <td>232</td>\n",
       "      <td>53.918785</td>\n",
       "      <td>208</td>\n",
       "      <td>89.439484</td>\n",
       "      <td>216</td>\n",
       "      <td>142.187988</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>88.797806</td>\n",
       "      <td>190</td>\n",
       "      <td>35.992794</td>\n",
       "      <td>139</td>\n",
       "      <td>21.363985</td>\n",
       "      <td>226</td>\n",
       "      <td>16.375364</td>\n",
       "      <td>311</td>\n",
       "      <td>16.375364</td>\n",
       "      <td>275</td>\n",
       "      <td>...</td>\n",
       "      <td>48.431953</td>\n",
       "      <td>173</td>\n",
       "      <td>48.885605</td>\n",
       "      <td>56</td>\n",
       "      <td>87.150803</td>\n",
       "      <td>304</td>\n",
       "      <td>48.431953</td>\n",
       "      <td>254</td>\n",
       "      <td>48.431953</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>215.114822</td>\n",
       "      <td>79</td>\n",
       "      <td>66.307434</td>\n",
       "      <td>82</td>\n",
       "      <td>124.288757</td>\n",
       "      <td>157</td>\n",
       "      <td>40.337471</td>\n",
       "      <td>222</td>\n",
       "      <td>40.977825</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>24.024097</td>\n",
       "      <td>170</td>\n",
       "      <td>63.339069</td>\n",
       "      <td>168</td>\n",
       "      <td>24.014111</td>\n",
       "      <td>233</td>\n",
       "      <td>63.339069</td>\n",
       "      <td>217</td>\n",
       "      <td>63.339069</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>29.146093</td>\n",
       "      <td>145</td>\n",
       "      <td>33.123096</td>\n",
       "      <td>151</td>\n",
       "      <td>31.249289</td>\n",
       "      <td>155</td>\n",
       "      <td>18.892790</td>\n",
       "      <td>225</td>\n",
       "      <td>24.645203</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>36.856098</td>\n",
       "      <td>308</td>\n",
       "      <td>39.549854</td>\n",
       "      <td>127</td>\n",
       "      <td>40.850422</td>\n",
       "      <td>216</td>\n",
       "      <td>42.251804</td>\n",
       "      <td>187</td>\n",
       "      <td>27.157705</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    per_of_RERERETE_semantics_0  seq_of_RERERETE_semantics_0  \\\n",
       "0                     49.683483                          179   \n",
       "1                     35.493668                           72   \n",
       "2                     18.961502                          152   \n",
       "3                     24.140652                           67   \n",
       "4                     51.526081                           76   \n",
       "..                          ...                          ...   \n",
       "95                    71.033676                          136   \n",
       "96                    14.939868                          160   \n",
       "97                    88.797806                          190   \n",
       "98                   215.114822                           79   \n",
       "99                    29.146093                          145   \n",
       "\n",
       "    per_of_RERERETE_semantics_1  seq_of_RERERETE_semantics_1  \\\n",
       "0                     97.792519                          146   \n",
       "1                     48.557602                           72   \n",
       "2                     42.149338                          100   \n",
       "3                     29.432497                           46   \n",
       "4                     45.434662                           78   \n",
       "..                          ...                          ...   \n",
       "95                   109.698463                          140   \n",
       "96                    12.893393                          153   \n",
       "97                    35.992794                          139   \n",
       "98                    66.307434                           82   \n",
       "99                    33.123096                          151   \n",
       "\n",
       "    per_of_RERERETE_semantics_2  seq_of_RERERETE_semantics_2  \\\n",
       "0                     94.723030                          195   \n",
       "1                     29.088301                           81   \n",
       "2                     32.718262                          162   \n",
       "3                     28.021360                           68   \n",
       "4                     60.044567                           82   \n",
       "..                          ...                          ...   \n",
       "95                    71.033676                          153   \n",
       "96                    26.084930                          162   \n",
       "97                    21.363985                          226   \n",
       "98                   124.288757                          157   \n",
       "99                    31.249289                          155   \n",
       "\n",
       "    per_of_RERERETE_semantics_3  seq_of_RERERETE_semantics_3  \\\n",
       "0                     12.597280                          288   \n",
       "1                     61.883507                          122   \n",
       "2                     13.673713                          171   \n",
       "3                     24.140652                           93   \n",
       "4                     48.849869                          231   \n",
       "..                          ...                          ...   \n",
       "95                    71.033676                          208   \n",
       "96                    55.187366                          207   \n",
       "97                    16.375364                          311   \n",
       "98                    40.337471                          222   \n",
       "99                    18.892790                          225   \n",
       "\n",
       "    per_of_RERERETE_semantics_4  seq_of_RERERETE_semantics_4  ...  \\\n",
       "0                     15.162140                          213  ...   \n",
       "1                     38.476810                           94  ...   \n",
       "2                     17.271112                          166  ...   \n",
       "3                     26.303492                           63  ...   \n",
       "4                     31.012699                          213  ...   \n",
       "..                          ...                          ...  ...   \n",
       "95                    79.333473                          182  ...   \n",
       "96                    38.400303                          181  ...   \n",
       "97                    16.375364                          275  ...   \n",
       "98                    40.977825                          192  ...   \n",
       "99                    24.645203                          163  ...   \n",
       "\n",
       "    per_of_RNormalTranslation_kwg_0  seq_of_RNormalTranslation_kwg_0  \\\n",
       "0                         40.119129                              303   \n",
       "1                         69.377960                              239   \n",
       "2                         11.553406                              330   \n",
       "3                         34.435089                              231   \n",
       "4                         71.921051                              308   \n",
       "..                              ...                              ...   \n",
       "95                       310.886993                              272   \n",
       "96                       109.062309                              308   \n",
       "97                        48.431953                              173   \n",
       "98                        24.024097                              170   \n",
       "99                        36.856098                              308   \n",
       "\n",
       "    per_of_RNormalTranslation_sir_0  seq_of_RNormalTranslation_sir_0  \\\n",
       "0                         40.119129                              197   \n",
       "1                        287.683105                              340   \n",
       "2                         11.553406                              495   \n",
       "3                         50.323181                               84   \n",
       "4                         70.718254                              117   \n",
       "..                              ...                              ...   \n",
       "95                       179.795166                              108   \n",
       "96                        53.918785                              232   \n",
       "97                        48.885605                               56   \n",
       "98                        63.339069                              168   \n",
       "99                        39.549854                              127   \n",
       "\n",
       "    per_of_RPivotTranslation_semantics_0  \\\n",
       "0                              33.094795   \n",
       "1                              74.275902   \n",
       "2                              43.565704   \n",
       "3                              60.475807   \n",
       "4                             170.488129   \n",
       "..                                   ...   \n",
       "95                            179.795166   \n",
       "96                             53.918785   \n",
       "97                             87.150803   \n",
       "98                             24.014111   \n",
       "99                             40.850422   \n",
       "\n",
       "    seq_of_RPivotTranslation_semantics_0  per_of_RPivotTranslation_kwg_0  \\\n",
       "0                                    227                       33.094795   \n",
       "1                                    161                       74.686523   \n",
       "2                                    250                       44.815575   \n",
       "3                                     93                       85.276672   \n",
       "4                                    237                       62.984909   \n",
       "..                                   ...                             ...   \n",
       "95                                   217                      179.795166   \n",
       "96                                   208                       89.439484   \n",
       "97                                   304                       48.431953   \n",
       "98                                   233                       63.339069   \n",
       "99                                   216                       42.251804   \n",
       "\n",
       "    seq_of_RPivotTranslation_kwg_0  per_of_RPivotTranslation_sir_0  \\\n",
       "0                              224                       33.094795   \n",
       "1                              230                       66.842415   \n",
       "2                              243                       11.553406   \n",
       "3                              166                       21.317049   \n",
       "4                              223                       71.921051   \n",
       "..                             ...                             ...   \n",
       "95                             188                      179.795166   \n",
       "96                             216                      142.187988   \n",
       "97                             254                       48.431953   \n",
       "98                             217                       63.339069   \n",
       "99                             187                       27.157705   \n",
       "\n",
       "    seq_of_RPivotTranslation_sir_0  \n",
       "0                              201  \n",
       "1                              137  \n",
       "2                              198  \n",
       "3                              242  \n",
       "4                              219  \n",
       "..                             ...  \n",
       "95                             246  \n",
       "96                             201  \n",
       "97                             237  \n",
       "98                             217  \n",
       "99                             190  \n",
       "\n",
       "[100 rows x 42 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for key in recursive_para.keys():\n",
    "    dfs.append(pd.DataFrame(recursive_para[key][0]))\n",
    "df = pd.concat(dfs , axis = 1)\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Per_ult1_ultimate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per_of_RERERETE_semantics_0</th>\n",
       "      <th>seq_of_RERERETE_semantics_0</th>\n",
       "      <th>per_of_RERERETE_semantics_1</th>\n",
       "      <th>seq_of_RERERETE_semantics_1</th>\n",
       "      <th>per_of_RERERETE_semantics_2</th>\n",
       "      <th>seq_of_RERERETE_semantics_2</th>\n",
       "      <th>per_of_RERERETE_semantics_3</th>\n",
       "      <th>seq_of_RERERETE_semantics_3</th>\n",
       "      <th>per_of_RERERETE_semantics_4</th>\n",
       "      <th>seq_of_RERERETE_semantics_4</th>\n",
       "      <th>...</th>\n",
       "      <th>per_of_RNormalTranslation_kwg_0</th>\n",
       "      <th>seq_of_RNormalTranslation_kwg_0</th>\n",
       "      <th>per_of_RNormalTranslation_sir_0</th>\n",
       "      <th>seq_of_RNormalTranslation_sir_0</th>\n",
       "      <th>per_of_RPivotTranslation_semantics_0</th>\n",
       "      <th>seq_of_RPivotTranslation_semantics_0</th>\n",
       "      <th>per_of_RPivotTranslation_kwg_0</th>\n",
       "      <th>seq_of_RPivotTranslation_kwg_0</th>\n",
       "      <th>per_of_RPivotTranslation_sir_0</th>\n",
       "      <th>seq_of_RPivotTranslation_sir_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.053815</td>\n",
       "      <td>147.510000</td>\n",
       "      <td>44.709146</td>\n",
       "      <td>135.640000</td>\n",
       "      <td>40.937385</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>35.445877</td>\n",
       "      <td>242.250000</td>\n",
       "      <td>37.459511</td>\n",
       "      <td>194.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.307177</td>\n",
       "      <td>283.830000</td>\n",
       "      <td>53.122877</td>\n",
       "      <td>209.970000</td>\n",
       "      <td>54.131676</td>\n",
       "      <td>229.400000</td>\n",
       "      <td>53.320258</td>\n",
       "      <td>225.540000</td>\n",
       "      <td>54.874228</td>\n",
       "      <td>223.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.004678</td>\n",
       "      <td>50.460405</td>\n",
       "      <td>35.830768</td>\n",
       "      <td>48.218886</td>\n",
       "      <td>34.417608</td>\n",
       "      <td>52.422237</td>\n",
       "      <td>25.036865</td>\n",
       "      <td>60.046678</td>\n",
       "      <td>28.224457</td>\n",
       "      <td>58.325519</td>\n",
       "      <td>...</td>\n",
       "      <td>48.773153</td>\n",
       "      <td>47.352761</td>\n",
       "      <td>46.072697</td>\n",
       "      <td>145.872606</td>\n",
       "      <td>47.450341</td>\n",
       "      <td>36.569845</td>\n",
       "      <td>41.066850</td>\n",
       "      <td>35.083859</td>\n",
       "      <td>47.350531</td>\n",
       "      <td>40.652288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.695521</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.058970</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.690650</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>6.296433</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>6.296433</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.242137</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>8.007092</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.752916</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>9.323277</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>8.242326</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.923317</td>\n",
       "      <td>119.750000</td>\n",
       "      <td>23.944107</td>\n",
       "      <td>109.750000</td>\n",
       "      <td>20.815385</td>\n",
       "      <td>140.750000</td>\n",
       "      <td>16.912510</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>17.288947</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.597847</td>\n",
       "      <td>266.500000</td>\n",
       "      <td>24.731002</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>28.824824</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>26.221711</td>\n",
       "      <td>203.750000</td>\n",
       "      <td>22.732635</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.428822</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>33.584003</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>30.664355</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>28.321187</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>28.518443</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.577257</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>39.840649</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>41.295092</td>\n",
       "      <td>227.500000</td>\n",
       "      <td>41.261217</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>36.082155</td>\n",
       "      <td>225.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.144745</td>\n",
       "      <td>182.250000</td>\n",
       "      <td>50.783721</td>\n",
       "      <td>161.750000</td>\n",
       "      <td>44.900572</td>\n",
       "      <td>198.250000</td>\n",
       "      <td>46.559510</td>\n",
       "      <td>288.750000</td>\n",
       "      <td>46.053268</td>\n",
       "      <td>238.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.597472</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>62.290608</td>\n",
       "      <td>329.750000</td>\n",
       "      <td>58.352207</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>60.635207</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>64.751614</td>\n",
       "      <td>245.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>227.854034</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>234.310791</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>176.275238</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>123.838623</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>154.057709</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>310.886993</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>287.683105</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>361.002045</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>194.025314</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>203.917236</td>\n",
       "      <td>318.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       per_of_RERERETE_semantics_0  seq_of_RERERETE_semantics_0  \\\n",
       "count                   100.000000                   100.000000   \n",
       "mean                     45.053815                   147.510000   \n",
       "std                      39.004678                    50.460405   \n",
       "min                       5.695521                    35.000000   \n",
       "25%                      20.923317                   119.750000   \n",
       "50%                      33.428822                   150.000000   \n",
       "75%                      52.144745                   182.250000   \n",
       "max                     227.854034                   341.000000   \n",
       "\n",
       "       per_of_RERERETE_semantics_1  seq_of_RERERETE_semantics_1  \\\n",
       "count                   100.000000                   100.000000   \n",
       "mean                     44.709146                   135.640000   \n",
       "std                      35.830768                    48.218886   \n",
       "min                       7.058970                    35.000000   \n",
       "25%                      23.944107                   109.750000   \n",
       "50%                      33.584003                   134.500000   \n",
       "75%                      50.783721                   161.750000   \n",
       "max                     234.310791                   342.000000   \n",
       "\n",
       "       per_of_RERERETE_semantics_2  seq_of_RERERETE_semantics_2  \\\n",
       "count                   100.000000                   100.000000   \n",
       "mean                     40.937385                   164.500000   \n",
       "std                      34.417608                    52.422237   \n",
       "min                       6.690650                    36.000000   \n",
       "25%                      20.815385                   140.750000   \n",
       "50%                      30.664355                   170.500000   \n",
       "75%                      44.900572                   198.250000   \n",
       "max                     176.275238                   345.000000   \n",
       "\n",
       "       per_of_RERERETE_semantics_3  seq_of_RERERETE_semantics_3  \\\n",
       "count                   100.000000                   100.000000   \n",
       "mean                     35.445877                   242.250000   \n",
       "std                      25.036865                    60.046678   \n",
       "min                       6.296433                    93.000000   \n",
       "25%                      16.912510                   207.000000   \n",
       "50%                      28.321187                   251.000000   \n",
       "75%                      46.559510                   288.750000   \n",
       "max                     123.838623                   351.000000   \n",
       "\n",
       "       per_of_RERERETE_semantics_4  seq_of_RERERETE_semantics_4  ...  \\\n",
       "count                   100.000000                   100.000000  ...   \n",
       "mean                     37.459511                   194.050000  ...   \n",
       "std                      28.224457                    58.325519  ...   \n",
       "min                       6.296433                    58.000000  ...   \n",
       "25%                      17.288947                   153.500000  ...   \n",
       "50%                      28.518443                   201.500000  ...   \n",
       "75%                      46.053268                   238.250000  ...   \n",
       "max                     154.057709                   368.000000  ...   \n",
       "\n",
       "       per_of_RNormalTranslation_kwg_0  seq_of_RNormalTranslation_kwg_0  \\\n",
       "count                       100.000000                       100.000000   \n",
       "mean                         54.307177                       283.830000   \n",
       "std                          48.773153                        47.352761   \n",
       "min                           8.242137                        92.000000   \n",
       "25%                          25.597847                       266.500000   \n",
       "50%                          39.577257                       295.000000   \n",
       "75%                          62.597472                       310.000000   \n",
       "max                         310.886993                       371.000000   \n",
       "\n",
       "       per_of_RNormalTranslation_sir_0  seq_of_RNormalTranslation_sir_0  \\\n",
       "count                       100.000000                       100.000000   \n",
       "mean                         53.122877                       209.970000   \n",
       "std                          46.072697                       145.872606   \n",
       "min                           8.007092                        45.000000   \n",
       "25%                          24.731002                        90.750000   \n",
       "50%                          39.840649                       153.000000   \n",
       "75%                          62.290608                       329.750000   \n",
       "max                         287.683105                       528.000000   \n",
       "\n",
       "       per_of_RPivotTranslation_semantics_0  \\\n",
       "count                            100.000000   \n",
       "mean                              54.131676   \n",
       "std                               47.450341   \n",
       "min                               12.752916   \n",
       "25%                               28.824824   \n",
       "50%                               41.295092   \n",
       "75%                               58.352207   \n",
       "max                              361.002045   \n",
       "\n",
       "       seq_of_RPivotTranslation_semantics_0  per_of_RPivotTranslation_kwg_0  \\\n",
       "count                            100.000000                      100.000000   \n",
       "mean                             229.400000                       53.320258   \n",
       "std                               36.569845                       41.066850   \n",
       "min                               93.000000                        9.323277   \n",
       "25%                              210.000000                       26.221711   \n",
       "50%                              227.500000                       41.261217   \n",
       "75%                              245.000000                       60.635207   \n",
       "max                              340.000000                      194.025314   \n",
       "\n",
       "       seq_of_RPivotTranslation_kwg_0  per_of_RPivotTranslation_sir_0  \\\n",
       "count                      100.000000                      100.000000   \n",
       "mean                       225.540000                       54.874228   \n",
       "std                         35.083859                       47.350531   \n",
       "min                        120.000000                        8.242326   \n",
       "25%                        203.750000                       22.732635   \n",
       "50%                        223.500000                       36.082155   \n",
       "75%                        243.000000                       64.751614   \n",
       "max                        349.000000                      203.917236   \n",
       "\n",
       "       seq_of_RPivotTranslation_sir_0  \n",
       "count                      100.000000  \n",
       "mean                       223.760000  \n",
       "std                         40.652288  \n",
       "min                        126.000000  \n",
       "25%                        201.000000  \n",
       "50%                        225.500000  \n",
       "75%                        245.250000  \n",
       "max                        318.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per_of_en_semantics_0</th>\n",
       "      <th>seq_of_en_semantics_0</th>\n",
       "      <th>per_of_en_kwg_0</th>\n",
       "      <th>seq_of_en_kwg_0</th>\n",
       "      <th>per_of_en_sir_0</th>\n",
       "      <th>seq_of_en_sir_0</th>\n",
       "      <th>per_of_inputs_en_0</th>\n",
       "      <th>seq_of_inputs_en_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.570123</td>\n",
       "      <td>316.770000</td>\n",
       "      <td>25.124003</td>\n",
       "      <td>337.050000</td>\n",
       "      <td>25.147391</td>\n",
       "      <td>239.39000</td>\n",
       "      <td>25.124003</td>\n",
       "      <td>323.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.000110</td>\n",
       "      <td>66.014516</td>\n",
       "      <td>18.821298</td>\n",
       "      <td>50.669931</td>\n",
       "      <td>18.885883</td>\n",
       "      <td>170.50945</td>\n",
       "      <td>18.821298</td>\n",
       "      <td>67.598891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.292984</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>3.292984</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>3.292984</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>3.292984</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.920447</td>\n",
       "      <td>317.750000</td>\n",
       "      <td>13.706877</td>\n",
       "      <td>333.750000</td>\n",
       "      <td>13.442638</td>\n",
       "      <td>97.00000</td>\n",
       "      <td>13.706877</td>\n",
       "      <td>319.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.264744</td>\n",
       "      <td>342.500000</td>\n",
       "      <td>19.033783</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>19.629847</td>\n",
       "      <td>164.50000</td>\n",
       "      <td>19.033783</td>\n",
       "      <td>353.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.192065</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>29.942201</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>30.351958</td>\n",
       "      <td>369.50000</td>\n",
       "      <td>29.942201</td>\n",
       "      <td>363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>286.005646</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>129.825012</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>129.825012</td>\n",
       "      <td>550.00000</td>\n",
       "      <td>129.825012</td>\n",
       "      <td>407.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       per_of_en_semantics_0  seq_of_en_semantics_0  per_of_en_kwg_0  \\\n",
       "count             100.000000             100.000000       100.000000   \n",
       "mean               53.570123             316.770000        25.124003   \n",
       "std                44.000110              66.014516        18.821298   \n",
       "min                 3.292984             106.000000         3.292984   \n",
       "25%                25.920447             317.750000        13.706877   \n",
       "50%                42.264744             342.500000        19.033783   \n",
       "75%                64.192065             356.000000        29.942201   \n",
       "max               286.005646             401.000000       129.825012   \n",
       "\n",
       "       seq_of_en_kwg_0  per_of_en_sir_0  seq_of_en_sir_0  per_of_inputs_en_0  \\\n",
       "count       100.000000       100.000000        100.00000          100.000000   \n",
       "mean        337.050000        25.147391        239.39000           25.124003   \n",
       "std          50.669931        18.885883        170.50945           18.821298   \n",
       "min         123.000000         3.292984         45.00000            3.292984   \n",
       "25%         333.750000        13.442638         97.00000           13.706877   \n",
       "50%         354.000000        19.629847        164.50000           19.033783   \n",
       "75%         365.000000        30.351958        369.50000           29.942201   \n",
       "max         407.000000       129.825012        550.00000          129.825012   \n",
       "\n",
       "       seq_of_inputs_en_0  \n",
       "count          100.000000  \n",
       "mean           323.810000  \n",
       "std             67.598891  \n",
       "min            110.000000  \n",
       "25%            319.750000  \n",
       "50%            353.000000  \n",
       "75%            363.000000  \n",
       "max            407.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in df.columns if 'en' in i ]\n",
    "df[a].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per_of_RERERETE_semantics_0\n",
      "seq_of_RERERETE_semantics_0\n",
      "per_of_RERERETE_semantics_1\n",
      "seq_of_RERERETE_semantics_1\n",
      "per_of_RERERETE_semantics_2\n",
      "seq_of_RERERETE_semantics_2\n",
      "per_of_RERERETE_semantics_3\n",
      "seq_of_RERERETE_semantics_3\n",
      "per_of_RERERETE_semantics_4\n",
      "seq_of_RERERETE_semantics_4\n",
      "per_of_RERERETE_kwg_0\n",
      "seq_of_RERERETE_kwg_0\n",
      "per_of_RERERETE_kwg_1\n",
      "seq_of_RERERETE_kwg_1\n",
      "per_of_RERERETE_kwg_2\n",
      "seq_of_RERERETE_kwg_2\n",
      "per_of_RERERETE_kwg_3\n",
      "seq_of_RERERETE_kwg_3\n",
      "per_of_RERERETE_kwg_4\n",
      "seq_of_RERERETE_kwg_4\n",
      "per_of_RERERETE_SIR_0\n",
      "seq_of_RERERETE_SIR_0\n",
      "per_of_RERERETE_SIR_1\n",
      "seq_of_RERERETE_SIR_1\n",
      "per_of_RERERETE_SIR_2\n",
      "seq_of_RERERETE_SIR_2\n",
      "per_of_RERERETE_SIR_3\n",
      "seq_of_RERERETE_SIR_3\n",
      "per_of_RERERETE_SIR_4\n",
      "seq_of_RERERETE_SIR_4\n",
      "per_of_RNormalTranslation_semantics_0\n",
      "seq_of_RNormalTranslation_semantics_0\n",
      "per_of_RNormalTranslation_kwg_0\n",
      "seq_of_RNormalTranslation_kwg_0\n",
      "per_of_RNormalTranslation_sir_0\n",
      "seq_of_RNormalTranslation_sir_0\n",
      "per_of_ReTranslatedRecusrive_semantics_0\n",
      "seq_of_ReTranslatedRecusrive_semantics_0\n",
      "per_of_ReTranslatedRecusrive_semantics_1\n",
      "seq_of_ReTranslatedRecusrive_semantics_1\n",
      "per_of_ReTranslatedRecusrive_semantics_2\n",
      "seq_of_ReTranslatedRecusrive_semantics_2\n",
      "per_of_ReTranslatedRecusrive_semantics_3\n",
      "seq_of_ReTranslatedRecusrive_semantics_3\n",
      "per_of_ReTranslatedRecusrive_semantics_4\n",
      "seq_of_ReTranslatedRecusrive_semantics_4\n",
      "per_of_ReTranslatedRecusrive_kwg_0\n",
      "seq_of_ReTranslatedRecusrive_kwg_0\n",
      "per_of_ReTranslatedRecusrive_kwg_1\n",
      "seq_of_ReTranslatedRecusrive_kwg_1\n",
      "per_of_ReTranslatedRecusrive_kwg_2\n",
      "seq_of_ReTranslatedRecusrive_kwg_2\n",
      "per_of_ReTranslatedRecusrive_kwg_3\n",
      "seq_of_ReTranslatedRecusrive_kwg_3\n",
      "per_of_ReTranslatedRecusrive_kwg_4\n",
      "seq_of_ReTranslatedRecusrive_kwg_4\n",
      "per_of_ReTranslatedRecusrive_SIR_0\n",
      "seq_of_ReTranslatedRecusrive_SIR_0\n",
      "per_of_ReTranslatedRecusrive_SIR_1\n",
      "seq_of_ReTranslatedRecusrive_SIR_1\n",
      "per_of_ReTranslatedRecusrive_SIR_2\n",
      "seq_of_ReTranslatedRecusrive_SIR_2\n",
      "per_of_ReTranslatedRecusrive_SIR_3\n",
      "seq_of_ReTranslatedRecusrive_SIR_3\n",
      "per_of_ReTranslatedRecusrive_SIR_4\n",
      "seq_of_ReTranslatedRecusrive_SIR_4\n",
      "per_of_RPivotTranslation_semantics_0\n",
      "seq_of_RPivotTranslation_semantics_0\n",
      "per_of_RPivotTranslation_kwg_0\n",
      "seq_of_RPivotTranslation_kwg_0\n",
      "per_of_RPivotTranslation_sir_0\n",
      "seq_of_RPivotTranslation_sir_0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
